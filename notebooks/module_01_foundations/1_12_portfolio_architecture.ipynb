{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 1.12: Portfolio Architecture — The Strategic View\n",
    "\n",
    "> **Goal:** Triage the business and identify where risk and investment lives.\n",
    "\n",
    "In Module 1.10, we computed Structure and Chaos scores for every series. Now we use those coordinates to build a strategic map of our portfolio.\n",
    "\n",
    "**This module answers:**\n",
    "- What does our portfolio look like on a Structure × Chaos map?\n",
    "- Which series are Stable? Complex? Messy? Low Signal?\n",
    "- Where is our revenue concentrated — and what's the risk profile?\n",
    "- Which departments need automation vs. human oversight?\n",
    "\n",
    "| Previous Module (1.10) | This Module (1.12) |\n",
    "|------------------------|--------------------|\n",
    "| Compute coordinates | Plot the map |\n",
    "| Sanity check metrics | Assign archetypes |\n",
    "| Output scores | Strategic triage |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Setup and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SETUP\n",
    "# =============================================================================\n",
    "\n",
    "# --- Imports ---\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- Path Configuration (before local imports) ---\n",
    "MODULE_DIR = Path().resolve()\n",
    "PROJECT_ROOT = MODULE_DIR.parent.parent\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "# --- Local Imports ---\n",
    "import tsforge as tsf\n",
    "from src import (\n",
    "    CacheManager,\n",
    "    ArtifactManager,\n",
    "    get_notebook_name\n",
    ")\n",
    "\n",
    "# --- Settings ---\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "\n",
    "# --- Paths ---\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# --- Managers ---\n",
    "NB_NAME = get_notebook_name()\n",
    "cache = CacheManager(PROJECT_ROOT / \".cache\" / NB_NAME)\n",
    "artifacts = ArtifactManager(PROJECT_ROOT / \"artifacts\")\n",
    "\n",
    "print(f\"✓ Setup complete | Root: {PROJECT_ROOT.name} | Module: {NB_NAME[:4]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load Scored Data from Module 1.10 ---\n",
    "scores_df = artifacts.load('1.10')\n",
    "print(f\"Loaded scores for {len(scores_df):,} series\")\n",
    "\n",
    "# --- Load Raw Time Series from Module 1.08 ---\n",
    "df = artifacts.load('1.08')\n",
    "print(f\"Loaded time series: {len(df):,} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview scores\n",
    "scores_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. The Structure × Chaos Map\n",
    "\n",
    "This is the core visualization: every series plotted by its Structure Score (y-axis) and Chaos Score (x-axis).\n",
    "\n",
    "**Reading the quadrants:**\n",
    "\n",
    "| Quadrant | Structure | Chaos | Archetype | Interpretation |\n",
    "|----------|-----------|-------|-----------|----------------|\n",
    "| Top-Left | High | Low | **Stable** | Predictable patterns, low noise → automate |\n",
    "| Top-Right | High | High | **Complex** | Strong patterns but also high noise → advanced models |\n",
    "| Bottom-Right | Low | High | **Messy** | No patterns, high noise → human oversight |\n",
    "| Bottom-Left | Low | Low | **Low Signal** | Neither patterns nor noise → simple baselines |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Baseline Method: Visual Split at 0.5\n",
    "\n",
    "The simplest approach: split at the midpoint (0.5) on each axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# THE STRUCTURE × CHAOS MAP\n",
    "# =============================================================================\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Scatter all series\n",
    "ax.scatter(\n",
    "    scores_df['chaos_score'], \n",
    "    scores_df['structure_score'],\n",
    "    alpha=0.3,\n",
    "    s=10,\n",
    "    c='#4A4E69',\n",
    "    edgecolors='none'\n",
    ")\n",
    "\n",
    "# Add quadrant lines at 0.5\n",
    "ax.axhline(y=0.5, color='#E94F37', linestyle='--', linewidth=2, alpha=0.7)\n",
    "ax.axvline(x=0.5, color='#E94F37', linestyle='--', linewidth=2, alpha=0.7)\n",
    "\n",
    "# Quadrant labels\n",
    "label_style = dict(fontsize=14, fontweight='bold', alpha=0.6)\n",
    "ax.text(0.25, 0.75, 'STABLE', ha='center', va='center', color='#2E86AB', **label_style)\n",
    "ax.text(0.75, 0.75, 'COMPLEX', ha='center', va='center', color='#8338EC', **label_style)\n",
    "ax.text(0.75, 0.25, 'MESSY', ha='center', va='center', color='#E94F37', **label_style)\n",
    "ax.text(0.25, 0.25, 'LOW SIGNAL', ha='center', va='center', color='#6C757D', **label_style)\n",
    "\n",
    "# Formatting\n",
    "ax.set_xlabel('Chaos Score →', fontsize=12)\n",
    "ax.set_ylabel('Structure Score →', fontsize=12)\n",
    "ax.set_title('Portfolio Architecture: Structure × Chaos Map', fontsize=14, fontweight='bold')\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "# Add count annotations\n",
    "n_total = len(scores_df)\n",
    "ax.text(0.02, 0.98, f'n = {n_total:,} series', transform=ax.transAxes, \n",
    "        fontsize=10, va='top', color='gray')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Advanced Method: K-Means Clustering (Optional)\n",
    "\n",
    "> **Advanced** — This section uses K-Means clustering to find natural groupings in the data. The details of K-Means are beyond our scope; we simply demonstrate that data-driven clustering largely confirms our visual quadrant split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ADVANCED: K-MEANS CLUSTERING\n",
    "# =============================================================================\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Fit K-Means with 4 clusters\n",
    "X = scores_df[['chaos_score', 'structure_score']].values\n",
    "kmeans = KMeans(n_clusters=4, random_state=42, n_init=10)\n",
    "scores_df['cluster_kmeans'] = kmeans.fit_predict(X)\n",
    "\n",
    "# Get cluster centers\n",
    "centers = kmeans.cluster_centers_\n",
    "\n",
    "print(\"K-Means Cluster Centers:\")\n",
    "print(\"-\" * 40)\n",
    "for i, (chaos, structure) in enumerate(centers):\n",
    "    print(f\"  Cluster {i}: Chaos={chaos:.3f}, Structure={structure:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot with K-Means clusters\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Color by cluster\n",
    "colors = ['#2E86AB', '#8338EC', '#E94F37', '#6C757D']\n",
    "for cluster_id in range(4):\n",
    "    mask = scores_df['cluster_kmeans'] == cluster_id\n",
    "    ax.scatter(\n",
    "        scores_df.loc[mask, 'chaos_score'],\n",
    "        scores_df.loc[mask, 'structure_score'],\n",
    "        alpha=0.3, s=10, c=colors[cluster_id], edgecolors='none',\n",
    "        label=f'Cluster {cluster_id} (n={mask.sum():,})'\n",
    "    )\n",
    "\n",
    "# Plot cluster centers\n",
    "ax.scatter(centers[:, 0], centers[:, 1], c='black', s=200, marker='X', \n",
    "           edgecolors='white', linewidths=2, zorder=5, label='Centroids')\n",
    "\n",
    "# Reference lines\n",
    "ax.axhline(y=0.5, color='gray', linestyle=':', linewidth=1, alpha=0.5)\n",
    "ax.axvline(x=0.5, color='gray', linestyle=':', linewidth=1, alpha=0.5)\n",
    "\n",
    "ax.set_xlabel('Chaos Score →', fontsize=12)\n",
    "ax.set_ylabel('Structure Score →', fontsize=12)\n",
    "ax.set_title('K-Means Clustering (k=4) vs. Visual Quadrants', fontsize=14, fontweight='bold')\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_aspect('equal')\n",
    "ax.legend(loc='upper left', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Assign Archetypes\n",
    "\n",
    "Using the baseline 0.5/0.5 split, we assign each series to one of four archetypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ASSIGN ARCHETYPES (BASELINE: 0.5 SPLIT)\n",
    "# =============================================================================\n",
    "\n",
    "def assign_archetype(row):\n",
    "    \"\"\"Assign archetype based on structure and chaos scores.\"\"\"\n",
    "    high_structure = row['structure_score'] >= 0.5\n",
    "    high_chaos = row['chaos_score'] >= 0.5\n",
    "    \n",
    "    if high_structure and not high_chaos:\n",
    "        return 'Stable'\n",
    "    elif high_structure and high_chaos:\n",
    "        return 'Complex'\n",
    "    elif not high_structure and high_chaos:\n",
    "        return 'Messy'\n",
    "    else:\n",
    "        return 'Low Signal'\n",
    "\n",
    "scores_df['archetype'] = scores_df.apply(assign_archetype, axis=1)\n",
    "\n",
    "# Distribution summary\n",
    "print(\"Archetype Distribution:\")\n",
    "print(\"=\" * 40)\n",
    "archetype_counts = scores_df['archetype'].value_counts()\n",
    "for archetype in ['Stable', 'Complex', 'Messy', 'Low Signal']:\n",
    "    count = archetype_counts.get(archetype, 0)\n",
    "    pct = count / len(scores_df) * 100\n",
    "    print(f\"  {archetype:12s}: {count:>6,} series ({pct:5.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview with archetypes\n",
    "scores_df[['unique_id', 'structure_score', 'chaos_score', 'archetype']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Hero Selection & Validation\n",
    "\n",
    "To validate that our map captures real behavioral differences, we select one **hero** series per quadrant:\n",
    "\n",
    "**Selection criteria:**\n",
    "- High volume (top decile) — we want series that matter\n",
    "- Near quadrant centroid — representative of the archetype\n",
    "- Not degenerate (no flat lines or extreme sparsity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Select Heroes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# COMPUTE VOLUME PER SERIES\n",
    "# =============================================================================\n",
    "\n",
    "# Total volume (sum of sales) per series\n",
    "volume_by_series = df.groupby('unique_id')['y'].sum().reset_index()\n",
    "volume_by_series.columns = ['unique_id', 'total_volume']\n",
    "\n",
    "# Merge with scores\n",
    "scores_df = scores_df.merge(volume_by_series, on='unique_id', how='left')\n",
    "\n",
    "# Identify top volume decile\n",
    "volume_p90 = scores_df['total_volume'].quantile(0.90)\n",
    "scores_df['high_volume'] = scores_df['total_volume'] >= volume_p90\n",
    "\n",
    "print(f\"Volume threshold (90th percentile): {volume_p90:,.0f}\")\n",
    "print(f\"High-volume series: {scores_df['high_volume'].sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SELECT HERO FOR EACH ARCHETYPE\n",
    "# =============================================================================\n",
    "\n",
    "# Define quadrant centroids (for distance calculation)\n",
    "centroids = {\n",
    "    'Stable': (0.25, 0.75),      # low chaos, high structure\n",
    "    'Complex': (0.75, 0.75),     # high chaos, high structure\n",
    "    'Messy': (0.75, 0.25),       # high chaos, low structure\n",
    "    'Low Signal': (0.25, 0.25)   # low chaos, low structure\n",
    "}\n",
    "\n",
    "heroes = {}\n",
    "\n",
    "for archetype, (cx, cy) in centroids.items():\n",
    "    # Filter to archetype + high volume\n",
    "    candidates = scores_df[\n",
    "        (scores_df['archetype'] == archetype) & \n",
    "        (scores_df['high_volume'])\n",
    "    ].copy()\n",
    "    \n",
    "    if len(candidates) == 0:\n",
    "        # Fall back to any series in archetype\n",
    "        candidates = scores_df[scores_df['archetype'] == archetype].copy()\n",
    "    \n",
    "    # Calculate distance to centroid\n",
    "    candidates['dist_to_centroid'] = np.sqrt(\n",
    "        (candidates['chaos_score'] - cx)**2 + \n",
    "        (candidates['structure_score'] - cy)**2\n",
    "    )\n",
    "    \n",
    "    # Select closest to centroid\n",
    "    hero_id = candidates.nsmallest(1, 'dist_to_centroid')['unique_id'].values[0]\n",
    "    heroes[archetype] = hero_id\n",
    "\n",
    "print(\"Selected Heroes:\")\n",
    "print(\"=\" * 50)\n",
    "for archetype, hero_id in heroes.items():\n",
    "    hero_data = scores_df[scores_df['unique_id'] == hero_id].iloc[0]\n",
    "    print(f\"  {archetype:12s}: {hero_id}\")\n",
    "    print(f\"               Structure={hero_data['structure_score']:.3f}, Chaos={hero_data['chaos_score']:.3f}\")\n",
    "    print(f\"               Volume={hero_data['total_volume']:,.0f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Hero Time Series (2×2 Facet)\n",
    "\n",
    "Let's visually confirm that our heroes actually look different from each other.\n",
    "\n",
    "> **Note:** No smoothers — we show raw truth for triage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# HERO TIME SERIES: 2×2 FACET\n",
    "# =============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "fig.suptitle('Hero Series by Archetype (Raw Signal)', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Define positions and colors\n",
    "archetype_config = {\n",
    "    'Stable': {'pos': (0, 0), 'color': '#2E86AB'},\n",
    "    'Complex': {'pos': (0, 1), 'color': '#8338EC'},\n",
    "    'Low Signal': {'pos': (1, 0), 'color': '#6C757D'},\n",
    "    'Messy': {'pos': (1, 1), 'color': '#E94F37'}\n",
    "}\n",
    "\n",
    "for archetype, config in archetype_config.items():\n",
    "    row, col = config['pos']\n",
    "    ax = axes[row, col]\n",
    "    color = config['color']\n",
    "    \n",
    "    hero_id = heroes[archetype]\n",
    "    hero_data = df[df['unique_id'] == hero_id].sort_values('ds')\n",
    "    hero_scores = scores_df[scores_df['unique_id'] == hero_id].iloc[0]\n",
    "    \n",
    "    # Plot raw time series\n",
    "    ax.plot(hero_data['ds'], hero_data['y'], color=color, linewidth=1.5, alpha=0.8)\n",
    "    ax.fill_between(hero_data['ds'], hero_data['y'], alpha=0.2, color=color)\n",
    "    \n",
    "    # Title with scores\n",
    "    ax.set_title(\n",
    "        f\"{archetype}\\n{hero_id}\\n\"\n",
    "        f\"Structure={hero_scores['structure_score']:.2f}, Chaos={hero_scores['chaos_score']:.2f}\",\n",
    "        fontsize=10, color=color, fontweight='bold'\n",
    "    )\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('Sales')\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Heroes on the Map\n",
    "\n",
    "Let's plot our heroes as labeled points on the scatter map to show where they fall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# MAP WITH HERO OVERLAY\n",
    "# =============================================================================\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Background scatter (all series, muted)\n",
    "ax.scatter(\n",
    "    scores_df['chaos_score'], \n",
    "    scores_df['structure_score'],\n",
    "    alpha=0.15, s=8, c='#4A4E69', edgecolors='none'\n",
    ")\n",
    "\n",
    "# Quadrant lines\n",
    "ax.axhline(y=0.5, color='#E94F37', linestyle='--', linewidth=2, alpha=0.5)\n",
    "ax.axvline(x=0.5, color='#E94F37', linestyle='--', linewidth=2, alpha=0.5)\n",
    "\n",
    "# Plot heroes with labels\n",
    "hero_colors = {\n",
    "    'Stable': '#2E86AB',\n",
    "    'Complex': '#8338EC',\n",
    "    'Messy': '#E94F37',\n",
    "    'Low Signal': '#6C757D'\n",
    "}\n",
    "\n",
    "for archetype, hero_id in heroes.items():\n",
    "    hero_data = scores_df[scores_df['unique_id'] == hero_id].iloc[0]\n",
    "    color = hero_colors[archetype]\n",
    "    \n",
    "    # Hero point\n",
    "    ax.scatter(\n",
    "        hero_data['chaos_score'], \n",
    "        hero_data['structure_score'],\n",
    "        s=200, c=color, edgecolors='white', linewidths=2, zorder=10,\n",
    "        marker='*'\n",
    "    )\n",
    "    \n",
    "    # Label\n",
    "    ax.annotate(\n",
    "        f\"{archetype}\\n{hero_id[:20]}...\",\n",
    "        xy=(hero_data['chaos_score'], hero_data['structure_score']),\n",
    "        xytext=(10, 10), textcoords='offset points',\n",
    "        fontsize=8, color=color, fontweight='bold',\n",
    "        bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8),\n",
    "        arrowprops=dict(arrowstyle='->', color=color, lw=1)\n",
    "    )\n",
    "\n",
    "# Quadrant labels (background)\n",
    "label_style = dict(fontsize=16, fontweight='bold', alpha=0.15)\n",
    "ax.text(0.25, 0.75, 'STABLE', ha='center', va='center', color='#2E86AB', **label_style)\n",
    "ax.text(0.75, 0.75, 'COMPLEX', ha='center', va='center', color='#8338EC', **label_style)\n",
    "ax.text(0.75, 0.25, 'MESSY', ha='center', va='center', color='#E94F37', **label_style)\n",
    "ax.text(0.25, 0.25, 'LOW SIGNAL', ha='center', va='center', color='#6C757D', **label_style)\n",
    "\n",
    "ax.set_xlabel('Chaos Score →', fontsize=12)\n",
    "ax.set_ylabel('Structure Score →', fontsize=12)\n",
    "ax.set_title('Portfolio Map with Hero Series', fontsize=14, fontweight='bold')\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Portfolio Composition (Wallet View)\n",
    "\n",
    "Now let's understand the portfolio breakdown:\n",
    "- What % of SKUs fall into each archetype?\n",
    "- What % of **volume** (revenue) falls into each archetype?\n",
    "\n",
    "These can be very different — a few high-volume SKUs might dominate revenue even if most SKUs are in a different quadrant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 SKU Count by Archetype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SKU COUNT BY ARCHETYPE\n",
    "# =============================================================================\n",
    "\n",
    "archetype_order = ['Stable', 'Complex', 'Messy', 'Low Signal']\n",
    "archetype_colors = ['#2E86AB', '#8338EC', '#E94F37', '#6C757D']\n",
    "\n",
    "sku_counts = scores_df['archetype'].value_counts().reindex(archetype_order)\n",
    "sku_pcts = sku_counts / sku_counts.sum() * 100\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "bars = ax.barh(archetype_order, sku_pcts, color=archetype_colors, edgecolor='white', height=0.6)\n",
    "\n",
    "# Add percentage labels\n",
    "for bar, pct, count in zip(bars, sku_pcts, sku_counts):\n",
    "    ax.text(bar.get_width() + 1, bar.get_y() + bar.get_height()/2,\n",
    "            f'{pct:.1f}% ({count:,})', va='center', fontsize=11)\n",
    "\n",
    "ax.set_xlabel('% of SKUs', fontsize=12)\n",
    "ax.set_title('Portfolio Composition: SKU Count by Archetype', fontsize=14, fontweight='bold')\n",
    "ax.set_xlim(0, max(sku_pcts) + 15)\n",
    "ax.invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Volume by Archetype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# VOLUME BY ARCHETYPE\n",
    "# =============================================================================\n",
    "\n",
    "volume_by_archetype = scores_df.groupby('archetype')['total_volume'].sum().reindex(archetype_order)\n",
    "volume_pcts = volume_by_archetype / volume_by_archetype.sum() * 100\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "bars = ax.barh(archetype_order, volume_pcts, color=archetype_colors, edgecolor='white', height=0.6)\n",
    "\n",
    "# Add percentage labels\n",
    "for bar, pct, vol in zip(bars, volume_pcts, volume_by_archetype):\n",
    "    ax.text(bar.get_width() + 1, bar.get_y() + bar.get_height()/2,\n",
    "            f'{pct:.1f}% ({vol/1e6:.1f}M units)', va='center', fontsize=11)\n",
    "\n",
    "ax.set_xlabel('% of Total Volume', fontsize=12)\n",
    "ax.set_title('Portfolio Composition: Volume by Archetype', fontsize=14, fontweight='bold')\n",
    "ax.set_xlim(0, max(volume_pcts) + 20)\n",
    "ax.invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# COMPARISON: SKU COUNT vs VOLUME\n",
    "# =============================================================================\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Archetype': archetype_order,\n",
    "    '% SKUs': sku_pcts.values,\n",
    "    '% Volume': volume_pcts.values\n",
    "})\n",
    "comparison_df['Concentration'] = comparison_df['% Volume'] / comparison_df['% SKUs']\n",
    "\n",
    "print(\"SKU Count vs Volume Comparison:\")\n",
    "print(\"=\" * 60)\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"\\nConcentration > 1 means archetype punches above its weight in volume.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. The Risk Matrix (Payoff Plot)\n",
    "\n",
    "The strategic payoff: **Where does revenue concentrate across Departments and Archetypes?**\n",
    "\n",
    "This matrix tells us:\n",
    "- Which departments are mostly Stable (→ automate)\n",
    "- Which departments have Messy/Complex concentration (→ human oversight, advanced models)\n",
    "- Where forecasting investment should focus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Build the Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EXTRACT DEPARTMENT FROM UNIQUE_ID\n",
    "# =============================================================================\n",
    "\n",
    "# M5 unique_id format: CATEGORY_DEPT_ITEM_STORE (e.g., FOODS_1_001_CA_1)\n",
    "# Department is the combination of CATEGORY_DEPT (e.g., FOODS_1, HOBBIES_2)\n",
    "\n",
    "scores_df['department'] = scores_df['unique_id'].apply(\n",
    "    lambda x: '_'.join(x.split('_')[:2])\n",
    ")\n",
    "\n",
    "print(\"Departments found:\")\n",
    "print(scores_df['department'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# BUILD DEPARTMENT × ARCHETYPE MATRIX\n",
    "# =============================================================================\n",
    "\n",
    "# Aggregate volume by department and archetype\n",
    "risk_matrix = scores_df.groupby(['department', 'archetype'])['total_volume'].sum().unstack(fill_value=0)\n",
    "\n",
    "# Reorder columns\n",
    "risk_matrix = risk_matrix[archetype_order]\n",
    "\n",
    "# Convert to percentages (row-wise: within each department)\n",
    "risk_matrix_pct = risk_matrix.div(risk_matrix.sum(axis=1), axis=0) * 100\n",
    "\n",
    "print(\"Department × Archetype Volume Distribution (%):\")\n",
    "risk_matrix_pct.round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# OPTION A: STACKED BAR CHART\n",
    "# =============================================================================\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Sort departments by total volume for meaningful ordering\n",
    "dept_order = risk_matrix.sum(axis=1).sort_values(ascending=True).index\n",
    "risk_matrix_sorted = risk_matrix_pct.reindex(dept_order)\n",
    "\n",
    "# Create stacked bar\n",
    "left = np.zeros(len(dept_order))\n",
    "for archetype, color in zip(archetype_order, archetype_colors):\n",
    "    values = risk_matrix_sorted[archetype].values\n",
    "    ax.barh(dept_order, values, left=left, label=archetype, color=color, height=0.7)\n",
    "    left += values\n",
    "\n",
    "ax.set_xlabel('% of Department Volume', fontsize=12)\n",
    "ax.set_ylabel('Department', fontsize=12)\n",
    "ax.set_title('Risk Matrix: Volume Distribution by Department × Archetype', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='lower right', fontsize=10)\n",
    "ax.set_xlim(0, 100)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# OPTION B: HEATMAP\n",
    "# =============================================================================\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Sort by total volume\n",
    "dept_order = risk_matrix.sum(axis=1).sort_values(ascending=False).index\n",
    "heatmap_data = risk_matrix_pct.reindex(dept_order)\n",
    "\n",
    "# Create heatmap\n",
    "im = ax.imshow(heatmap_data.values, cmap='YlOrRd', aspect='auto')\n",
    "\n",
    "# Set ticks\n",
    "ax.set_xticks(range(len(archetype_order)))\n",
    "ax.set_xticklabels(archetype_order, fontsize=11)\n",
    "ax.set_yticks(range(len(dept_order)))\n",
    "ax.set_yticklabels(dept_order, fontsize=11)\n",
    "\n",
    "# Add text annotations\n",
    "for i in range(len(dept_order)):\n",
    "    for j in range(len(archetype_order)):\n",
    "        value = heatmap_data.values[i, j]\n",
    "        text_color = 'white' if value > 50 else 'black'\n",
    "        ax.text(j, i, f'{value:.0f}%', ha='center', va='center', \n",
    "                color=text_color, fontsize=10, fontweight='bold')\n",
    "\n",
    "ax.set_xlabel('Archetype', fontsize=12)\n",
    "ax.set_ylabel('Department', fontsize=12)\n",
    "ax.set_title('Risk Matrix Heatmap: % Volume by Department × Archetype', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Colorbar\n",
    "cbar = plt.colorbar(im, ax=ax, shrink=0.8)\n",
    "cbar.set_label('% of Department Volume', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Strategic Callouts\n",
    "\n",
    "Let's extract actionable insights from the risk matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STRATEGIC INSIGHTS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Strategic Insights by Department:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for dept in risk_matrix_pct.index:\n",
    "    row = risk_matrix_pct.loc[dept]\n",
    "    dominant = row.idxmax()\n",
    "    dominant_pct = row.max()\n",
    "    \n",
    "    # Determine recommendation\n",
    "    stable_pct = row['Stable']\n",
    "    messy_pct = row['Messy']\n",
    "    complex_pct = row['Complex']\n",
    "    \n",
    "    if stable_pct >= 60:\n",
    "        recommendation = \"→ AUTOMATE: High stability, simple models suffice\"\n",
    "    elif messy_pct >= 40:\n",
    "        recommendation = \"→ GOVERNANCE: High chaos, needs human-in-loop oversight\"\n",
    "    elif complex_pct >= 40:\n",
    "        recommendation = \"→ INVEST: High complexity, advanced models can capture signal\"\n",
    "    else:\n",
    "        recommendation = \"→ MIXED: Differentiated approach needed\"\n",
    "    \n",
    "    print(f\"\\n{dept}:\")\n",
    "    print(f\"  Dominant: {dominant} ({dominant_pct:.0f}%)\")\n",
    "    print(f\"  Breakdown: Stable={stable_pct:.0f}%, Complex={complex_pct:.0f}%, Messy={messy_pct:.0f}%\")\n",
    "    print(f\"  {recommendation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Department Context (Optional)\n",
    "\n",
    "For scale context, we can view aggregated department-level time series.\n",
    "\n",
    "> ⚠️ **GUARDRAIL:** Aggregation hides chaos. These plots show **scale**, not **classification**. Do not use aggregated patterns to infer archetype — that's what SKU-level scores are for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# AGGREGATED DEPARTMENT TIME SERIES\n",
    "# =============================================================================\n",
    "\n",
    "# Extract department from raw data\n",
    "df['department'] = df['unique_id'].apply(lambda x: '_'.join(x.split('_')[:2]))\n",
    "\n",
    "# Get top departments by volume\n",
    "top_depts = df.groupby('department')['y'].sum().nlargest(5).index.tolist()\n",
    "\n",
    "print(f\"Top 5 departments by volume: {top_depts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PLOT AGGREGATED SERIES\n",
    "# =============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(len(top_depts), 1, figsize=(14, 3*len(top_depts)), sharex=True)\n",
    "fig.suptitle('Department-Level Aggregated Demand (Scale Context Only)', \n",
    "             fontsize=14, fontweight='bold', y=1.02)\n",
    "\n",
    "for idx, dept in enumerate(top_depts):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Aggregate to department level\n",
    "    dept_data = df[df['department'] == dept].groupby('ds')['y'].sum().reset_index()\n",
    "    \n",
    "    # Get archetype breakdown for this department\n",
    "    dept_breakdown = risk_matrix_pct.loc[dept]\n",
    "    \n",
    "    # Plot\n",
    "    ax.plot(dept_data['ds'], dept_data['y'], color='#4A4E69', linewidth=1.2)\n",
    "    ax.fill_between(dept_data['ds'], dept_data['y'], alpha=0.2, color='#4A4E69')\n",
    "    \n",
    "    # Title with archetype breakdown\n",
    "    breakdown_str = ', '.join([f\"{a}={v:.0f}%\" for a, v in dept_breakdown.items() if v > 5])\n",
    "    ax.set_title(f\"{dept} | {breakdown_str}\", fontsize=11, loc='left')\n",
    "    ax.set_ylabel('Units')\n",
    "\n",
    "axes[-1].set_xlabel('Date')\n",
    "\n",
    "# Add guardrail note\n",
    "fig.text(0.5, -0.02, \n",
    "         '⚠️ Aggregation hides SKU-level chaos. This view shows scale, not forecastability.',\n",
    "         ha='center', fontsize=10, color='#E94F37', style='italic')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Key Takeaways\n",
    "\n",
    "### What the Map Revealed\n",
    "\n",
    "| Finding | Implication |\n",
    "|---------|-------------|\n",
    "| Portfolio composition by archetype | [Fill in: e.g., \"60% of SKUs are Stable\"] |\n",
    "| Volume concentration | [Fill in: e.g., \"80% of revenue is in Stable+Complex\"] |\n",
    "| Department risk profiles | [Fill in: e.g., \"FOODS is mostly stable; HOBBIES is mostly messy\"] |\n",
    "\n",
    "### Strategic Recommendations by Archetype\n",
    "\n",
    "| Archetype | % Volume | Recommended Approach |\n",
    "|-----------|----------|----------------------|\n",
    "| **Stable** | XX% | Automate with simple models (ETS, Prophet) |\n",
    "| **Complex** | XX% | Invest in advanced models (ML, deep learning) |\n",
    "| **Messy** | XX% | Human-in-loop governance, sanity checks |\n",
    "| **Low Signal** | XX% | Simple baselines, don't overfit |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SAVE FINAL OUTPUT\n",
    "# =============================================================================\n",
    "\n",
    "# Save scores with archetypes for downstream use\n",
    "output_cols = ['unique_id', 'department', 'structure_score', 'chaos_score', \n",
    "               'archetype', 'total_volume']\n",
    "final_output = scores_df[output_cols].copy()\n",
    "\n",
    "artifacts.save(\n",
    "    final_output,\n",
    "    name='1.12',\n",
    "    description='Portfolio architecture: SKU archetypes and scores'\n",
    ")\n",
    "\n",
    "print(f\"✓ Saved artifact '1.12' with {len(final_output):,} series\")\n",
    "print(f\"  Columns: {list(final_output.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "With our portfolio mapped and triaged, we can now:\n",
    "\n",
    "1. **Build archetype-specific forecasting strategies** — different models for different behaviors\n",
    "2. **Set appropriate accuracy expectations** — Stable series should hit <10% MAPE; Messy series might be 30%+\n",
    "3. **Allocate resources intelligently** — invest modeling effort where it can actually help\n",
    "4. **Design monitoring dashboards** — track performance by archetype, catch degradation early\n",
    "\n",
    "> **The map is the strategy.** Every forecasting decision should flow from this triage."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ts_forge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
