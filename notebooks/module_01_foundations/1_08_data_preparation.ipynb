{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 1.8: Data Preparation\n",
    "\n",
    "> **Goal:** Transform first-contact data into a forecast-ready dataset.\n",
    "\n",
    "**Module Type:** Transformation\n",
    "\n",
    "| Input | Output |\n",
    "|-------|--------|\n",
    "| `1_06.parquet` (raw weekly data) | `1_08.parquet` (forecast-ready) |\n",
    "| `1_06.json` (raw state report) | `1_08.json` (prepared state + decisions) |\n",
    "\n",
    "By the end of this module, you'll have a dataset that is:\n",
    "- **Continuous in time** â€” no missing weeks\n",
    "- **Properly imputed** â€” domain-appropriate fill policy\n",
    "- **Enriched with features** â€” known-at-time calendar attributes\n",
    "- **Documented** â€” all decisions logged and traceable\n",
    "\n",
    "| Step | What | Why |\n",
    "|------|------|-----|\n",
    "| 1 | Load + Review Prior State | Understand what we're starting with |\n",
    "| 2 | Fill Gaps | Complete weekly timeline for every series |\n",
    "| 3 | Impute Target | Apply domain-appropriate fill policy |\n",
    "| 4 | Merge Calendar | Add known-at-time features |\n",
    "| 5 | Document & Save | Log all decisions, compare to prior |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Setup complete | Root: real-world-forecasting-foundations\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SETUP\n",
    "# =============================================================================\n",
    "\n",
    "# --- Imports ---\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utilsforecast.preprocessing import fill_gaps\n",
    "\n",
    "# --- Path Configuration ---\n",
    "MODULE_DIR = Path().resolve()\n",
    "PROJECT_ROOT = MODULE_DIR.parent.parent\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "# --- Local Imports ---\n",
    "from src import (\n",
    "    CacheManager,\n",
    "    first_contact_check,\n",
    "    load_m5_calendar,\n",
    "    aggregate_calendar_to_weekly,\n",
    ")\n",
    "\n",
    "# --- Settings ---\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "\n",
    "# --- Managers ---\n",
    "cache = CacheManager(MODULE_DIR / \".cache\")\n",
    "outputs = CacheManager(PROJECT_ROOT / \"outputs\")\n",
    "\n",
    "print(f\"âœ“ Setup complete | Root: {PROJECT_ROOT.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Load & Review Prior State\n",
    "\n",
    "Load from Module 1.06 and understand what we're starting with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš  Cache '1_06' not found\n"
     ]
    }
   ],
   "source": [
    "# Load prior module's output + report\n",
    "df, prior_report = outputs.load('1_06', with_report=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Starting State (from 1.06):\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'summary_table'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Review prior state\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mðŸ“Š Starting State (from 1.06):\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mprior_report\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummary_table\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'summary_table'"
     ]
    }
   ],
   "source": [
    "# Review prior state\n",
    "print(\"ðŸ“Š Starting State (from 1.06):\")\n",
    "prior_report.summary_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for issues to fix\n",
    "prior_report.table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Diagnose Gaps\n",
    "\n",
    "How many series have missing weeks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected number of weeks per series\n",
    "date_range = df['ds'].agg(['min', 'max'])\n",
    "expected_weeks = ((date_range['max'] - date_range['min']).days // 7) + 1\n",
    "\n",
    "# Actual weeks per series\n",
    "actual_weeks = df.groupby('unique_id')['ds'].nunique()\n",
    "\n",
    "# Series with gaps\n",
    "series_with_gaps = (actual_weeks < expected_weeks).sum()\n",
    "total_series = df['unique_id'].nunique()\n",
    "\n",
    "print(f\"Expected weeks per series: {expected_weeks}\")\n",
    "print(f\"Series with gaps: {series_with_gaps:,} / {total_series:,} ({series_with_gaps/total_series:.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Fill Gaps\n",
    "\n",
    "Ensure every series has a complete weekly timeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill gaps using Nixtla's fill_gaps\n",
    "# This creates rows for missing dates with NA values\n",
    "df_filled = fill_gaps(\n",
    "    df,\n",
    "    freq='W-SAT',  # Walmart fiscal week\n",
    "    start=None,    # Use min date per series\n",
    "    end=None       # Use max date per series\n",
    ")\n",
    "\n",
    "print(f\"Before: {len(df):,} rows\")\n",
    "print(f\"After:  {len(df_filled):,} rows\")\n",
    "print(f\"Added:  {len(df_filled) - len(df):,} gap rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add gap flag for traceability\n",
    "df_filled['is_gap'] = df_filled['y'].isna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Impute Target\n",
    "\n",
    "Fill NA values with domain-appropriate strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count NAs before imputation\n",
    "na_before = df_filled['y'].isna().sum()\n",
    "print(f\"NAs before imputation: {na_before:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation strategy: Zero fill\n",
    "# Rationale: In retail, missing data typically means no sales occurred\n",
    "df_filled['y'] = df_filled['y'].fillna(0)\n",
    "\n",
    "na_after = df_filled['y'].isna().sum()\n",
    "print(f\"NAs after imputation: {na_after:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Merge Calendar Features\n",
    "\n",
    "Add known-at-time calendar attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Load & Aggregate Calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw daily calendar\n",
    "calendar = load_m5_calendar(PROJECT_ROOT / 'data')\n",
    "calendar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate to weekly\n",
    "weekly_calendar = aggregate_calendar_to_weekly(calendar)\n",
    "weekly_calendar.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Merge with Sales Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge on date\n",
    "df_merged = df_filled.merge(weekly_calendar, on='ds', how='left')\n",
    "\n",
    "print(f\"Columns before: {df_filled.shape[1]}\")\n",
    "print(f\"Columns after:  {df_merged.shape[1]}\")\n",
    "print(f\"Added: {df_merged.shape[1] - df_filled.shape[1]} calendar features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 What We're NOT Adding (Yet)\n",
    "\n",
    "| Feature | Why Excluded | When to Add |\n",
    "|---------|--------------|-------------|\n",
    "| Price features | Requires lagging to avoid leakage | Feature Engineering module |\n",
    "| Lag features | Created during model training | Modeling module |\n",
    "| Outlier flags | Need baseline forecast first | Post-baseline module |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Document & Save\n",
    "\n",
    "Create final report with all decisions logged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Create Report with Decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create report for prepared data\n",
    "report = first_contact_check(\n",
    "    df_merged, \n",
    "    dataset_name='1.08 Prepared',\n",
    "    prior_module='1_06'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log all decisions\n",
    "report.log_decision(\n",
    "    step='Gap Detection',\n",
    "    decision='datetime_diagnostics()',\n",
    "    assumption='Weekly frequency is correct',\n",
    "    reversible=True,\n",
    "    note='Re-run with different freq if needed'\n",
    ")\n",
    "\n",
    "report.log_decision(\n",
    "    step='Gap Filling',\n",
    "    decision=\"fill_gaps(freq='W-SAT')\",\n",
    "    assumption='Series should span full date range',\n",
    "    reversible=True,\n",
    "    note='is_gap flag preserved for traceability'\n",
    ")\n",
    "\n",
    "report.log_decision(\n",
    "    step='Imputation',\n",
    "    decision='NA â†’ 0',\n",
    "    assumption='Missing = no sales (retail domain)',\n",
    "    reversible=True,\n",
    "    note='Can re-impute using is_gap flag'\n",
    ")\n",
    "\n",
    "report.log_decision(\n",
    "    step='Calendar Merge',\n",
    "    decision='Weekly aggregation (events: any, SNAP: max)',\n",
    "    assumption='One event day = event week',\n",
    "    reversible=True,\n",
    "    note='Raw calendar available for different aggregation'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 View Data Evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show what changed\n",
    "report.evolution(prior_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show decisions made\n",
    "report.decisions_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or use combined display\n",
    "report.evolution_display(prior_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Final Report Card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Save Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to outputs/01_foundations/\n",
    "outputs.save(\n",
    "    df=df_merged,\n",
    "    key='1_08',\n",
    "    unit='01_foundations',\n",
    "    report=report,\n",
    "    config={\n",
    "        'freq': 'W-SAT',\n",
    "        'imputation': 'zero',\n",
    "        'calendar_merged': True,\n",
    "        'gaps_filled': True\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Summary\n",
    "\n",
    "### What We Did\n",
    "\n",
    "| Step | Before | After |\n",
    "|------|--------|-------|\n",
    "| Gap Filling | Series with gaps | Continuous timeline |\n",
    "| Imputation | NAs in target | All values filled |\n",
    "| Calendar Merge | 8 columns | 20+ columns |\n",
    "\n",
    "### Key Assumptions\n",
    "\n",
    "1. **Missing data = no sales** â€” Zero fill is domain-appropriate for retail\n",
    "2. **Events: any-in-week** â€” If any day in week had event, week is flagged\n",
    "3. **SNAP: max-in-week** â€” If any day had SNAP, week is flagged\n",
    "4. **Fiscal week: Sun-Sat** â€” Walmart's calendar, not ISO week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "| Module | Focus |\n",
    "|--------|-------|\n",
    "| **1.11** | Plotting & visual diagnostics |\n",
    "| **2.01** | Baseline models â€” naive, seasonal naive |\n",
    "| **2.02** | Statistical models â€” ETS, ARIMA |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ts_forge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
