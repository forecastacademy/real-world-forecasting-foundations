{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.07: Model Performance Diagnostics - Detailed Forensics (Micro Level)\n",
    "\n",
    "## OPENING\n",
    "\n",
    "In the last module, we ran portfolio diagnostics. We found where the fire is — which segments are driving 80% of the error, whether that error is bias or variance, and whether the model is stable.\n",
    "\n",
    "That's **triage**. Now we **investigate**.\n",
    "\n",
    "In this notebook, we go detective mode: pulling representative SKUs from high-impact segments, inspecting their forecasts visually, analyzing residuals, and finding the **smoking guns** — specific patterns the model is missing.\n",
    "\n",
    "**Critical:** We're not cherry-picking. We're not debugging anecdotes. We're looking for **failure signatures that generalize** — patterns we can fix systematically in Module 3.\n",
    "\n",
    "The output isn't a score. It's a **bug report** — the requirements document for feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SETUP: Load Dependencies and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "\n",
    "sns.set_theme()\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load forecasts and actuals from cross-validation\n",
    "# Expected columns: sku_id, date, actual, forecast, model_name, fold_id\n",
    "cv_forecasts = pd.read_csv('path/to/cv_forecasts.csv')\n",
    "diagnostics_backlog = pd.read_csv('priority_segments_for_2.7.csv')  # From 2.06\n",
    "\n",
    "print(f\"Loaded {len(cv_forecasts)} forecast records\")\n",
    "print(f\"Columns: {cv_forecasts.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## SECTION 1: THE SNIFF TEST IS A DISCIPLINE\n",
    "\n",
    "### Visual Trust Matters\n",
    "\n",
    "Sometimes a model passes all the metrics but produces a forecast that just looks... wrong. Straight line through obvious seasonality. Weird step functions. Negative demand.\n",
    "\n",
    "This is the **Uncanny Valley of Forecasting**. The math passes, but reality fails.\n",
    "\n",
    "Visual trust is part of system performance. A forecast that looks plausible will get used. A forecast that looks crazy will get overridden.\n",
    "\n",
    "### The Sniff Test Checklist\n",
    "\n",
    "When you look at a forecast plot, you're checking for:\n",
    "- **Level:** Does it anchor to recent reality, or does it jump?\n",
    "- **Shape:** Does the seasonal shape match history?\n",
    "- **Trend:** Does it drift reasonably, or explode into infinity?\n",
    "- **Negatives:** Negative demand = immediate fail\n",
    "- **Step Changes:** Does it acknowledge known discontinuities?\n",
    "- **Smoothness:** Is it overly smooth or overly reactive?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## SECTION 2: CASE SELECTION STRATEGY (DON'T CHERRY PICK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get SKUs from high-impact segments identified in 2.06\n",
    "# Representative sampling: 3-5 SKUs per quadrant\n",
    "\n",
    "selected_skus = []\n",
    "\n",
    "# From diagnostics_backlog, sample representative SKUs\n",
    "for segment in diagnostics_backlog['segment'].unique():\n",
    "    segment_skus = cv_forecasts[cv_forecasts['category'] == segment]['sku_id'].unique()\n",
    "    # Sample 3-5 random SKUs from each high-impact segment\n",
    "    sample_size = min(5, len(segment_skus))\n",
    "    sampled = np.random.choice(segment_skus, size=sample_size, replace=False)\n",
    "    selected_skus.extend(sampled)\n",
    "\n",
    "selected_skus = list(set(selected_skus))\n",
    "print(f\"Selected {len(selected_skus)} SKUs for forensic investigation\")\n",
    "print(f\"SKU List: {selected_skus[:10]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## SECTION 3: VISUAL INSPECTION WORKFLOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_timeseries_inspection(sku_id, cv_forecasts, num_periods=52):\n",
    "    \"\"\"\n",
    "    Visual inspection plot: actuals vs forecasts\n",
    "    \"\"\"\n",
    "    sku_data = cv_forecasts[cv_forecasts['sku_id'] == sku_id].sort_values('date')\n",
    "    \n",
    "    if len(sku_data) == 0:\n",
    "        print(f\"No data for SKU {sku_id}\")\n",
    "        return\n",
    "    \n",
    "    # Take last num_periods for clarity\n",
    "    sku_data = sku_data.tail(num_periods)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 6))\n",
    "    \n",
    "    # Plot actuals\n",
    "    ax.plot(sku_data['date'], sku_data['actual'], \n",
    "            marker='o', label='Actual', linewidth=2, color='black')\n",
    "    \n",
    "    # Plot forecasts by model\n",
    "    for model in sku_data['model_name'].unique():\n",
    "        model_data = sku_data[sku_data['model_name'] == model]\n",
    "        ax.plot(model_data['date'], model_data['forecast'], \n",
    "                marker='s', label=f'Forecast: {model}', alpha=0.7, linewidth=1.5)\n",
    "    \n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('Demand')\n",
    "    ax.set_title(f'Sniff Test: SKU {sku_id}')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return sku_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sniff test checklist for visual inspection\n",
    "def run_sniff_test(sku_data):\n",
    "    \"\"\"\n",
    "    Structured checklist for visual inspection\n",
    "    \"\"\"\n",
    "    checks = {}\n",
    "    \n",
    "    # Level check: recent forecast vs actual\n",
    "    recent_actual = sku_data['actual'].tail(4).mean()\n",
    "    recent_forecast = sku_data['forecast'].tail(4).mean()\n",
    "    level_ratio = recent_forecast / recent_actual if recent_actual > 0 else 0\n",
    "    checks['level_check'] = 'PASS' if 0.8 <= level_ratio <= 1.2 else 'FAIL'\n",
    "    \n",
    "    # Negative check\n",
    "    has_negatives = (sku_data['forecast'] < 0).any()\n",
    "    checks['negative_check'] = 'FAIL' if has_negatives else 'PASS'\n",
    "    \n",
    "    # Trend check: does forecast change reasonably?\n",
    "    forecast_std = sku_data['forecast'].std()\n",
    "    actual_std = sku_data['actual'].std()\n",
    "    volatility_ratio = forecast_std / actual_std if actual_std > 0 else 0\n",
    "    checks['trend_check'] = 'PASS' if 0.1 <= volatility_ratio <= 3 else 'FLAG'\n",
    "    \n",
    "    return checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## SECTION 4: RESIDUALS ARE THE CRIME SCENE\n",
    "\n",
    "### What Residuals Tell You\n",
    "\n",
    "Residuals = Actual - Forecast\n",
    "\n",
    "If residuals are random noise, the model captured everything forecastable. If residuals have patterns, the model missed something.\n",
    "\n",
    "**Residuals are the crime scene.** We're looking for smoking guns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_residuals(sku_data):\n",
    "    \"\"\"\n",
    "    Comprehensive residual analysis\n",
    "    \"\"\"\n",
    "    # Calculate residuals\n",
    "    sku_data = sku_data.copy()\n",
    "    sku_data['residual'] = sku_data['actual'] - sku_data['forecast']\n",
    "    sku_data['abs_error'] = np.abs(sku_data['residual'])\n",
    "    sku_data['pct_error'] = (sku_data['residual'] / (sku_data['actual'] + 1)) * 100\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(\"Residual Summary:\")\n",
    "    print(f\"  Mean (Bias): {sku_data['residual'].mean():.2f}\")\n",
    "    print(f\"  Std Dev: {sku_data['residual'].std():.2f}\")\n",
    "    print(f\"  Min: {sku_data['residual'].min():.2f}\")\n",
    "    print(f\"  Max: {sku_data['residual'].max():.2f}\")\n",
    "    \n",
    "    return sku_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_residuals(sku_data, sku_id):\n",
    "    \"\"\"\n",
    "    Three-view residual plot: signed error, abs error, rolling bias\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(14, 10))\n",
    "    \n",
    "    # View 1: Signed residuals (error over time)\n",
    "    axes[0].bar(range(len(sku_data)), sku_data['residual'], \n",
    "                color=['red' if x < 0 else 'green' for x in sku_data['residual']])\n",
    "    axes[0].axhline(y=0, color='black', linestyle='--', linewidth=1)\n",
    "    axes[0].set_title(f'SKU {sku_id}: Signed Residuals (Actual - Forecast)')\n",
    "    axes[0].set_ylabel('Error')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # View 2: Absolute error over time\n",
    "    axes[1].plot(range(len(sku_data)), sku_data['abs_error'], \n",
    "                 marker='o', color='orange', linewidth=2)\n",
    "    axes[1].set_title('Absolute Error Over Time')\n",
    "    axes[1].set_ylabel('|Error|')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # View 3: Rolling bias (4-period rolling average)\n",
    "    rolling_bias = sku_data['residual'].rolling(window=4, center=True).mean()\n",
    "    axes[2].plot(range(len(sku_data)), rolling_bias, \n",
    "                 marker='s', color='purple', linewidth=2, label='4-week rolling bias')\n",
    "    axes[2].axhline(y=0, color='black', linestyle='--', linewidth=1)\n",
    "    axes[2].set_title('Rolling Bias (4-Period Window)')\n",
    "    axes[2].set_xlabel('Time Period')\n",
    "    axes[2].set_ylabel('Bias')\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_failure_signatures(sku_data):\n",
    "    \"\"\"\n",
    "    Identify smoking guns in residuals\n",
    "    \"\"\"\n",
    "    signatures = {}\n",
    "    \n",
    "    # 1. Autocorrelation (missed trend)\n",
    "    residual_corr = sku_data['residual'].autocorr(lag=1)\n",
    "    signatures['autocorrelation'] = {\n",
    "        'value': residual_corr,\n",
    "        'signal': 'HIGH' if abs(residual_corr) > 0.5 else 'LOW',\n",
    "        'smoking_gun': 'Missed trend or momentum' if abs(residual_corr) > 0.5 else None\n",
    "    }\n",
    "    \n",
    "    # 2. Seasonality in residuals (missed seasonal component)\n",
    "    if len(sku_data) >= 52:\n",
    "        seasonal_corr = sku_data['residual'].autocorr(lag=52)\n",
    "        signatures['seasonality'] = {\n",
    "            'value': seasonal_corr,\n",
    "            'signal': 'HIGH' if seasonal_corr > 0.3 else 'LOW',\n",
    "            'smoking_gun': 'Missed seasonal component' if seasonal_corr > 0.3 else None\n",
    "        }\n",
    "    \n",
    "    # 3. Level shift (regime change)\n",
    "    first_half = sku_data['residual'].iloc[:len(sku_data)//2].mean()\n",
    "    second_half = sku_data['residual'].iloc[len(sku_data)//2:].mean()\n",
    "    shift_magnitude = abs(second_half - first_half)\n",
    "    signatures['level_shift'] = {\n",
    "        'value': shift_magnitude,\n",
    "        'signal': 'HIGH' if shift_magnitude > sku_data['residual'].std() else 'LOW',\n",
    "        'smoking_gun': 'Regime change or structural shift' if shift_magnitude > sku_data['residual'].std() else None\n",
    "    }\n",
    "    \n",
    "    return signatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## SECTION 5: MODEL VS DATA VS POLICY TRIAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triage_problem_type(smoking_gun_description):\n",
    "    \"\"\"\n",
    "    Classify problem into three categories: Model, Data, or Policy\n",
    "    \"\"\"\n",
    "    # This is a rule-based classification that can be expanded\n",
    "    \n",
    "    model_keywords = ['trend', 'seasonal', 'holiday', 'promo', 'promotion', 'event']\n",
    "    data_keywords = ['stockout', 'gap', 'null', 'error', 'freeze']\n",
    "    policy_keywords = ['sporadic', 'intermittent', 'chaotic', 'unforecastable']\n",
    "    \n",
    "    description_lower = smoking_gun_description.lower()\n",
    "    \n",
    "    if any(keyword in description_lower for keyword in model_keywords):\n",
    "        return 'MODEL_PROBLEM', 'Add features in Module 3'\n",
    "    elif any(keyword in description_lower for keyword in data_keywords):\n",
    "        return 'DATA_PROBLEM', 'Clean the data pipeline'\n",
    "    elif any(keyword in description_lower for keyword in policy_keywords):\n",
    "        return 'POLICY_PROBLEM', 'Use min/max inventory rules, not precision forecasting'\n",
    "    else:\n",
    "        return 'UNKNOWN', 'Requires further investigation'\n",
    "\n",
    "# Example: triage a potential smoking gun\n",
    "example_smoking_gun = \"Residual spikes align with holidays and promotions\"\n",
    "problem_type, fix = triage_problem_type(example_smoking_gun)\n",
    "print(f\"Example Smoking Gun: {example_smoking_gun}\")\n",
    "print(f\"Problem Type: {problem_type}\")\n",
    "print(f\"Fix: {fix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## SECTION 6: FORENSIC INVESTIGATION SUMMARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile forensic findings into backlog for Module 3\n",
    "forensic_backlog = []\n",
    "\n",
    "# For each selected SKU, run full investigation and collect findings\n",
    "for sku_id in selected_skus[:3]:  # Start with first 3 for demonstration\n",
    "    sku_data = cv_forecasts[cv_forecasts['sku_id'] == sku_id].sort_values('date')\n",
    "    \n",
    "    if len(sku_data) > 10:\n",
    "        sku_data = analyze_residuals(sku_data)\n",
    "        sniff_test = run_sniff_test(sku_data)\n",
    "        signatures = detect_failure_signatures(sku_data)\n",
    "        \n",
    "        forensic_backlog.append({\n",
    "            'sku_id': sku_id,\n",
    "            'sniff_test_pass': all(v == 'PASS' for v in sniff_test.values()),\n",
    "            'primary_smoking_gun': next((v['smoking_gun'] for v in signatures.values() if v['smoking_gun']), None),\n",
    "            'requires_investigation': not all(v == 'PASS' for v in sniff_test.values())\n",
    "        })\n",
    "\n",
    "forensic_df = pd.DataFrame(forensic_backlog)\n",
    "print(\"\\nForensic Investigation Results:\")\n",
    "print(forensic_df.to_string(index=False))\n",
    "\n",
    "# Save for Module 3\n",
    "forensic_df.to_csv('forensic_findings_for_module_3.csv', index=False)\n",
    "print(\"\\n✓ Forensic findings saved to 'forensic_findings_for_module_3.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
